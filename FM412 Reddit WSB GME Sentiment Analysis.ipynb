{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a739442",
   "metadata": {},
   "source": [
    "This is a programme for FM412 Group Assignment 1 Part 2 r/WSB GME related sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case in the new environment there is no local packages\n",
    "'''\n",
    "pip install psaw\n",
    "pip install praw\n",
    "pip install nltk\n",
    "pip install timestamp\n",
    "pip install emoji\n",
    "pip install re\n",
    "pip install transformers\n",
    "pip install seaborn\n",
    "pip install matplotlib\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304dcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "from psaw import PushshiftAPI\n",
    "from transformers import AutoTokenizer as AT\n",
    "from transformers import AutoModelForSequenceClassification as AM # The above two to use the pretrained model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49484f",
   "metadata": {},
   "source": [
    "I will scrapy the submissions and comments about GME from the begining of 2021.01.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924c3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = int(dt.datetime(2021, 1, 1).timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb39c6",
   "metadata": {},
   "source": [
    "Construct API Query for searching submissions containing GME as keyword in the subreddit r/wsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c4fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "GME_submissions = api.search_submissions(after = start_time, q = 'GME', subreddit = 'wallstreetbets', limit = 10)\n",
    "# search for submissions that containing GME\n",
    "GME_comments = api.search_comments(after = start_time, q = 'GME', subreddit = 'wallstreetbets', limit = 10)\n",
    "# search for comments that containing GME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9a32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_submissions = []\n",
    "text_comments = []\n",
    "for rows in GME_submissions:\n",
    "    if rows.title.find('GME') != -1:\n",
    "        text_submissions.append(rows.title)\n",
    "    if rows.selftext.find('GME') != -1:\n",
    "        text_submissions.append(rows.selftext)\n",
    "for items in GME_comments:\n",
    "    text_comments.append(items.body)\n",
    "# Combining two texts\n",
    "text = text_submissions + text_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50316cde",
   "metadata": {},
   "source": [
    "By now, we have got all the text information from Reddit, we will now proceed to sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66f648",
   "metadata": {},
   "source": [
    "Preprosessing the text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c889d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text, get unique items\n",
    "def get_unique_text(text):\n",
    "    list_of_unique_text = []\n",
    "    unique_text = set(text)\n",
    "    for text in unique_text:\n",
    "        list_of_unique_text.append(text)\n",
    "    return list_of_unique_text\n",
    "text = get_unique_text(text) # Get the distinct texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60e442a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62dd373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$ISPO Could it squeeze similar to $GME? Since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!banbet GME 100 1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a pin for gme on wsb? Color me surprised! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15k open interest GME 950 C for 1/20/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I called you a dumbass in a GME thread because...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  $ISPO Could it squeeze similar to $GME? Since ...\n",
       "1                                 !banbet GME 100 1d\n",
       "2  Wow a pin for gme on wsb? Color me surprised! ...\n",
       "3            15k open interest GME 950 C for 1/20/23\n",
       "4  I called you a dumbass in a GME thread because..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(text), columns = ['text'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3d130",
   "metadata": {},
   "source": [
    "One must install pytorch and then use the pretrained package. Go to http://pytorch.org \n",
    "\n",
    "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio===0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086b5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the pretrained sentiment analysis package\n",
    "tokenizer = AT.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AM.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3834d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will map the sentiment number with each title\n",
    "def sentiment_classifier(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors = 'pt', add_special_tokens = True)\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    input_ids = inputs['input_ids']\n",
    "    output = model(input_ids, token_type_ids, return_dict = True, output_hidden_states = True)\n",
    "    logits = np.array(output.logits.tolist()[0])\n",
    "    prob = np.exp(logits)/np.sum(np.exp(logits))\n",
    "    return np.sum([(x+1)*prob[x] for x in range(len(prob))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b2e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['text'].apply(lambda x: sentiment_classifier(x[:512], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2452275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$ISPO Could it squeeze similar to $GME? Since ...</td>\n",
       "      <td>1.720743</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!banbet GME 100 1d</td>\n",
       "      <td>2.776648</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow a pin for gme on wsb? Color me surprised! ...</td>\n",
       "      <td>4.552956</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15k open interest GME 950 C for 1/20/23</td>\n",
       "      <td>3.519945</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I called you a dumbass in a GME thread because...</td>\n",
       "      <td>1.147833</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$50k+ GME YOLO ðŸš€ðŸš€ðŸš€ Hedgies R Fuk !!! DRS is th...</td>\n",
       "      <td>2.787308</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Just ask, I'll tell you.   fuck the GME cult, ...</td>\n",
       "      <td>1.626596</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOL. I opened after commenting. Yep. GME Meltd...</td>\n",
       "      <td>1.253565</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maximum TFSA YOLO! Letâ€™s go GME ðŸš€</td>\n",
       "      <td>3.963553</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>**Ban Bet Created:** **/u/CantStop_GameStop** ...</td>\n",
       "      <td>1.419017</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GME TO 40$</td>\n",
       "      <td>2.192010</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Been here since Jan and bough my first share o...</td>\n",
       "      <td>4.442420</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GME will dump 5% in the last 30 minutes today....</td>\n",
       "      <td>1.673692</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GME to the moon?</td>\n",
       "      <td>2.443725</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>So, I was actually curious if the existence of...</td>\n",
       "      <td>2.018201</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Could the masses turn MULN into the next GME? ...</td>\n",
       "      <td>1.725349</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>With the recent posts about GME Apes losing it...</td>\n",
       "      <td>2.281932</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nah, it obviously means you are bought by Melv...</td>\n",
       "      <td>1.893959</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Final Order: GME Earnings YOLO update. Coh...</td>\n",
       "      <td>1.886351</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  sentiment  attitude\n",
       "0   $ISPO Could it squeeze similar to $GME? Since ...   1.720743  Negative\n",
       "1                                  !banbet GME 100 1d   2.776648  Positive\n",
       "2   Wow a pin for gme on wsb? Color me surprised! ...   4.552956  Positive\n",
       "3             15k open interest GME 950 C for 1/20/23   3.519945  Positive\n",
       "4   I called you a dumbass in a GME thread because...   1.147833  Negative\n",
       "5   $50k+ GME YOLO ðŸš€ðŸš€ðŸš€ Hedgies R Fuk !!! DRS is th...   2.787308  Positive\n",
       "6   Just ask, I'll tell you.   fuck the GME cult, ...   1.626596  Negative\n",
       "7   LOL. I opened after commenting. Yep. GME Meltd...   1.253565  Negative\n",
       "8                   Maximum TFSA YOLO! Letâ€™s go GME ðŸš€   3.963553  Positive\n",
       "9   **Ban Bet Created:** **/u/CantStop_GameStop** ...   1.419017  Negative\n",
       "10                                         GME TO 40$   2.192010  Positive\n",
       "11  Been here since Jan and bough my first share o...   4.442420  Positive\n",
       "12  GME will dump 5% in the last 30 minutes today....   1.673692  Negative\n",
       "13                                   GME to the moon?   2.443725  Positive\n",
       "14  So, I was actually curious if the existence of...   2.018201  Positive\n",
       "15  Could the masses turn MULN into the next GME? ...   1.725349  Negative\n",
       "16  With the recent posts about GME Apes losing it...   2.281932  Positive\n",
       "17  Nah, it obviously means you are bought by Melv...   1.893959  Negative\n",
       "18  The Final Order: GME Earnings YOLO update. Coh...   1.886351  Negative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping the attitude\n",
    "df['attitude'] = 0\n",
    "df.loc[df['sentiment'] > 2, 'attitude'] = 'Positive'\n",
    "df.loc[df['sentiment'] < 2, 'attitude'] = 'Negative'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7941f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could the masses turn MULN into the next GME? This company is 45% shorted at the moment...'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[15] # Sentiment: 1.72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2229f3fe",
   "metadata": {},
   "source": [
    "It can be seen that the sentence marked as 1.7, which should be relatively negative sentence has appeared positive to GME itself. The reason it is marked as 1.7 because it complained about other things.\n",
    "It can be shown in after cells that people are using a cynical and complaining tones. When their sentiments are marked below 2.5, which should be recognised as negative, but actually are positive to GME. It tells us that the market is irrational,unlike in the normal time when they phrase the good stocks.\n",
    "Therefore, to adjust the change, it is reasonable to set the bar of negative/positive as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9578f461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nah, it obviously means you are bought by Melvin Capital and Citadel and you had lunch with Vlad Tenev today to orchestrate a planned shutdown of WSB and RH at the same time to stop purchases from accelerating the price of GME to $69,420,420 and also your dad is Jerome Powell and the SEC and they made love to create you.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[17] # Sentiment: 1.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0051ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Final Order: GME Earnings YOLO update. Cohen you little tardling. Put up or shut up fool'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[18] # Sentiment: 1.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7f9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I called you a dumbass in a GME thread because you're not on a GME forum, this is open discussion for anyone with any opinion about it. And my opinion is that you're delusional, sad, stupid, and throwing good money after bad in a quixotic attempt to catch a wave that already made it to shore 14 months ago\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[4] # This sentiment is marked as 1.14 which is near to the lower limit of sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b20f44",
   "metadata": {},
   "source": [
    "As one can see, even though I put some of truly positive comments to negative, it also shows that the positive views are more than the negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a5e5943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attitude\n",
       "Positive        10\n",
       "Negative         9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df.attitude.value_counts().to_frame()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "714d5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(name, start_time, limit, subreddit, benchmark):\n",
    "    api = PushshiftAPI()\n",
    "    GME_submissions = api.search_submissions(after = start_time, q = name, subreddit = subreddit, limit = limit)\n",
    "    # search for submissions that containing GME\n",
    "    GME_comments = api.search_comments(after = start_time, q = name, subreddit = subreddit, limit = limit)\n",
    "    # search for comments that containing GME\n",
    "    \n",
    "    # Delete texts without keyword and append them in the same list\n",
    "    text_submissions = []\n",
    "    text_comments = []\n",
    "    for rows in GME_submissions:\n",
    "        if rows.title.find(name) != -1:\n",
    "            text_submissions.append(rows.title)\n",
    "        # When submission is high, it returns no selftext\n",
    "        #if rows.selftext.find(name) != -1:\n",
    "            #text_submissions.append(rows.selftext)\n",
    "    for items in GME_comments:\n",
    "        text_comments.append(items.body)\n",
    "    # Combining two texts\n",
    "    text = text_submissions + text_comments\n",
    "    \n",
    "    # Cleaning text, get unique items\n",
    "    def get_unique_text(text):\n",
    "        list_of_unique_text = []\n",
    "        unique_text = set(text)\n",
    "        for text in unique_text:\n",
    "            list_of_unique_text.append(text)\n",
    "        return list_of_unique_text\n",
    "    text = get_unique_text(text) # Get the distinct texts\n",
    "    \n",
    "    # Making a pandas dataframe\n",
    "    df = pd.DataFrame(np.array(text), columns = ['text'])\n",
    "    \n",
    "    # Natural Language Processing with pre_trained package 'Bert'\n",
    "    tokenizer = AT.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    model = AM.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    \n",
    "    def sentiment_classifier(text, model, tokenizer):\n",
    "        inputs = tokenizer.encode_plus(text, return_tensors = 'pt', add_special_tokens = True)\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        input_ids = inputs['input_ids']\n",
    "        output = model(input_ids, token_type_ids, return_dict = True, output_hidden_states = True)\n",
    "        logits = np.array(output.logits.tolist()[0])\n",
    "        prob = np.exp(logits)/np.sum(np.exp(logits))\n",
    "        return np.sum([(x+1)*prob[x] for x in range(len(prob))])\n",
    "    \n",
    "    # Mapping sentiment and attitudes with text\n",
    "    df['sentiment'] = df['text'].apply(lambda x: sentiment_classifier(x[:512], model, tokenizer))\n",
    "    df['attitude'] = 0\n",
    "    df.loc[df['sentiment'] > benchmark, 'attitude'] = 'Positive'\n",
    "    df.loc[df['sentiment'] < benchmark, 'attitude'] = 'Negative'\n",
    "    \n",
    "    # Reducing the counts\n",
    "    counts = df.attitude.value_counts().to_frame()\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3956dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>10932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attitude\n",
       "Positive     10932\n",
       "Negative      4643"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data to be used in report, with 20k sample space \n",
    "\n",
    "df = main(name = 'GME', start_time = start_time, subreddit = 'wallstreetbets', limit = 10000, benchmark = 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ab1147e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude</th>\n",
       "      <th>percentage%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>10932</td>\n",
       "      <td>70.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>4643</td>\n",
       "      <td>29.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          attitude  percentage%\n",
       "Positive     10932        70.19\n",
       "Negative      4643        29.81"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['percentage%'] = round((df['attitude']/df['attitude'].sum())*100, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
